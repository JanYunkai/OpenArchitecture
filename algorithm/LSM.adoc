== Log Structured Merge Trees(LSM)

> 简单来说，LSM被设计来提供比传统的B+树或者ISAM更好的写操作吞吐量，通过消去随机的本地更新操作来达到这个目标(顺序读写快，随机读写慢)。

因为简单和高效，基于日志的策略在大数据之间越来越流行，同时他们也有一些缺点，从日志中读一些数据将会比写操作需要更多的时间，需要倒序扫描，直接找到所需要的内容。

这说明日志仅适用于一些简单的读场景：

. 数据是整体访问，像大部分数据库的WAL（write-ahead log）
. 知道明确的offset，比如在kafka中

所以需要更多的日志来为更复杂的读场景（比如按key或者range）提供高效的性能，这儿有4个方法可以完成这个，他们分别是：

. 二分查找：将文件数据有序保存，使用二分查找来完成特定key的查找。
. 哈希：用哈希将数据分割为不同的bucket
. B+树：使用B+树或者ISAM等方法，可以减少外部文件的读取
. 外部文件：将数据保存为日志，并创建一个hash或者查找树映射相关的文件

=== The Base LSM Algorithm



### 附录

. 磁盘的理论速度 200-300 MB/s
. 支持copy-on-write tree（通过顺序在文件末尾重复写对结构来实现写操作，之前的树结构相关部分，包括最顶层节点都会变成孤节点。尽管通过这种方法避免了本地更新，但是因为每个操作都要重写树结构，放大了写操作，降低了写性能）。