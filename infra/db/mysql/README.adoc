== mysql

=== 事务

事务是由一组SQL语句组成的逻辑处理单元，事务具有以下4个属性，通常简称ACID属性。


* 原子性（Atomicity）

事务是一个原子操作单元，其对数据的修改，要么全部执行，要么全部不执行。

* 一致性（Consistent）

在事务开始和完成时，数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以保持数据的完整性；事务结束时，所有的内部数据结构（如B树索引或双向链表）也都必须是正确的。

* 隔离性（Isolation）

数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响到“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的，反之亦然。

* 持久性（Durability）

事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。


==== 事务隔离级别

|===
|隔离级别|隔离级别的值|导致的问题|用例

|Read-Uncommitted(读未提交)
|0
|有脏读
|

|Read-committed(读提交)
|1
|无脏读，允许不可重复读和幻读
|SqlServer、Oracle

|Repeatable-read（重复读）
|2
|无脏读和不可重复读，允许幻读
|Mysql Inndb

|Serializable（串行化）
|3
|都可以避免，执行效率慢，慎用
|
|===

* 脏读

事务A读取到了事务B已修改但尚未提交的数据，还在这个数据基础上做了操作。

* 不可重复读

事务A读取到了事务B已经提交的修改数据，不符合隔离性

* 幻读

第一个事务对一定范围的数据进行批量修改，第二个事务在这个范围内增加一条数据，这时候第一个事务就会丢失对新增数据的修改

== 分库分表

=== 分表的根本原因

分库分表应该拆分为分表、分库，一般来说先进行分表，分表的原动力在于MySQL的单表性能问题，据说Mysql单表数据量超过N千万、或者表Size大于N+G性能就不行了。这个说法背后的逻辑是数据量超过一定大小，B+Tree索引高度就会增加，而没增加一层高度，整个索引扫描就会多一次IO。其实更关键在于应用本身的使用，如果多数是索引命中率很高的点查或小范围查，其实这个上线还很高。但正是业务的不可控，所以大家往往采取比较保守的策略，这就是分表的原因。

=== 分库+分表的根本原因

分库主要由于MySQL容量上，Mysql的写入是很昂贵的操作，它本身有很多优化技术，即使如此，写入也存在放大很多倍的现象。同时Mysql M-S的架构虽然天然地支持读流量扩展，但由于Mysql从库默认采用单线程的SQL thread进行Binlog顺序重放，这种单线程的从库写入极大地限制整个集群的写入能力，（除非不在意数据延迟，而数据延迟与否直接影响了读数据的可用性）。Mysql基于组替吉奥的并行复制从某种程度上缓解了这个问题，但本质上写入上限还是非常容易达到（实际业务几千的TPS），目前一些云RDS通过计算存储分离、log is database的理念来很大程度上解决了写入扩大的问题，但在这之前，更为普遍的解决方案就是把一个集群拆分为N个集群，即分库分表（sharding）。为了规避热点问题，绝大多数采用的方法就是hash切分，也有极少的范围、或者基于Mapping的查询切分。

== 分库分表方案

=== DB Proxy

DBproxy 高度依赖网络组件，它需要诸如LVS/F5等VIP来实现流量的负载均衡，如果跨IDC，还依赖诸如DNS进行IDC分发。同时部分DBproxy对Prepare这类操作支持不友好，所以概括来说：

. 链路过长，每层都会增加响应时间
. 网络单点，并且往往是整个公司层面的单点
. 部分产品对Prepare应用不友好，需要绑定connection信息

==== Mycat

> 基于proxy，复写MySQL协议，将Mycat Server伪装成一个MySQL数据库

缺点：

1. 需要独立维护高可用性

== JDBC Proxy

JDBC Proxy最大的问题是违背了DB透明的原则，它需要对不同的语言编写Driver，概括来说：

* 语言限制
* 接入繁琐
* DB 不透明

=== Sharding-JDBC

> 基于JDBC接口的扩展，是以jar包的形式提供轻量级服务


== Sharding成本汇总

=== 应用限制

* DB弱化成存储
* 跨DB事务、全局约束难实现
* SQL聚合，join，子查询限制

=== 拆分Key不易选择

=== 算法选择

* Hash、Range、Mapping每种算法都有短板
* 算法转换成本极大

=== 强一致性无法保证

=== 业务多维度

* 数据冗余
* 数据一致性保证
* 数据同步
** 双写
** 异步同步
** Canal、Databus、MQ、DataX

=== 全局ID复杂实现

=== 高可用扩散问题

* MGR、PXC都有各自的问题
* MHA切换准确率、时间成本

=== 弹性、再扩容成本超大

=== 容量与资源成本

* 分少了需要再扩容，分多了浪费资源

=== 改造兼容性

* 业务能等到时间很短
* 需要高昂的技术储备

=== 运维成本

* DDL变更更重，OSC工具存在隐患
* 需要自动化运维

=== OLAP业务需要重复资源

* 人力
* 产品：ETL、Hive、HBase、Hadoop


分库分表为了解决一个问题，引入了很多成本，从长久看这种方案会逐步被新的解决方案替代。

* 第一个思路既然分库的原动力主要是单实例的写入容量限制，那么我们可以最大程度地提升整个写入容量，云计算的发展为这种思路提供了新的可能，以AWS Aurora为代表RDS，它以Log is database为理念，将复杂的随机读写简化为顺序写到Log，并通过将计算与存储分离，把复杂的数据持久化、一致性、数据合并都扔给高可用的共享存储系统来完成，进而打开写入的天花板，将昂贵的写入容量提升一个量级。

* 第二种思路承认分片的必要性，将这种分片策略集成到一套整体的分布式数据库体系中，同时通过Paxos/Raft复制协议和加上多实例节点来实现数据一致的高可用，其中代表产品有Google点Spanner&F1、Tidb、CockRoachDB等，是比较理想的Sharding+Proxy的替代方案。

== 附录

* https://juejin.cn/post/6937150983210450957?utm_source=gold_browser_extension[一文带你读懂MySQL锁机制]
* https://www.yuque.com/ccazhw/tuacvk[Mycat1权威指南]
* https://www.yuque.com/ccazhw/ml3nkf[Mycat2权威指南]
* https://dbaplus.cn/news-11-1854-1.html[方案虽好，成本先行：数据库Sharding+Proxy实践解析]